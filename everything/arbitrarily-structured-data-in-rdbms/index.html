<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <title>shazow | Andrey Petrov</title>

    <link href="https://shazow.net/css/base.css?4" media="screen" rel="stylesheet" type="text/css" />
    <link rel="icon" type="image/png" href="https://shazow.net/images/icon.png" />

    <link href='//fonts.googleapis.com/css?family=OFL+Sorts+Mill+Goudy+TT:400,400italic&amp;v2' rel='stylesheet' type='text/css'>
    
</head>


<body>


<div class="back">&larr; <a href="https://shazow.net/">Back to shazow.net</a></div>
<section class="main post container">
    <div class="front-matter">
        <div class="title-container">
            <div class="initials"><a href="https://shazow.net/"></a></div>
        </div>
        <div class="meta">
            
            <div class="date" title='Wed Oct 20 2010 16:01:53 -0700'>Published on Oct 20, 2010.</div>
            
        </div>
    </div>
    <div>
        

<h1 id="arbitrarily-structured-data-in-relational-databases">Arbitrarily-Structured Data in Relational Databases</h1>

<p>This approach is similar to <a href="http://bret.appspot.com/entry/how-friendfeed-uses-mysql">FriendFeed&rsquo;s schemaless database framework</a>. The key difference is in the data locality.</p>

<p>The goal is <em>not</em> to build an effective schemaless database on top of a relational database, but rather to accomodate for rapidly-evolving relational schemas and reducing the difficult of migrating forward.</p>

<h2 id="hypothesis">Hypothesis</h2>

<p>In an evolving relational (SQL) database schema, we store two types of data: Data we will be querying against and data we will be displaying. There is often a subset of display data which will not be used for querying in the foreseeable future, and this is the data whose structure changes most often.</p>

<h2 id="solution">Solution</h2>

<p>Store query data and display data separately such that display data is less strictly-structured and thus more easily evolved.</p>

<p>Imagine a standardized table structure where each table has the following columns: <code>id</code>, <code>time_created</code>, <code>time_updated</code>, <code>_data</code>, and additional &ldquo;index columns&rdquo;.</p>

<p>The <code>_data</code> column contains a dictionary of arbitrary data serialized into JSON (or could be zlib-compressed Pickle if it were Python-specific). Index columns are columns which you query against.</p>

<h3 id="example">Example</h3>

<p>A typical <em>user</em> table might have the following columns (using an SQLAlchemy declarative model):</p>

<pre><code class="language-python">class User(Model):

    id = Column(types.Integer, primary_key=True)
    time_created = Column(types.DateTime, default=datetime.now, nullable=False)
    time_updated = Column(types.DateTime, onupdate=datetime.now)

    is_admin = Column(types.Boolean, default=False, nullable=False)

    email = Column(types.String(255), nullable=False, index=True, unique=True)
    display_name = Column(types.String(64))

    password_hash = Column(types.String(40), nullable=False)
    password_salt = Column(types.String(8), nullable=False)
</code></pre>

<p>In our example, this table will have two types of queries:</p>

<pre><code class="language-sql">-- Load the user object from the current session (where we store the user_id)
SELECT * FROM user WHERE id = :user_id;

-- Check the given password against the email address, for login
SELECT password_hash, password_salt FROM user WHERE email = :user_email;
</code></pre>

<p>In the schemaless model, the table would look like this:</p>

<pre><code class="language-python">class User(SchemalessModel):

    id = Column(types.Integer, primary_key=True)
    time_created = Column(types.DateTime, default=datetime.now, nullable=False)
    time_updated = Column(types.DateTime, onupdate=datetime.now)
    _data = Column(types.JSON)

    email = Column(types.String(255), nullable=False, index=True, unique=True)
</code></pre>

<p>Where the <code>_data</code> column would contain data like this:</p>

<pre><code class="language-javascript">{
    &quot;display_name&quot;: &quot;Andrey Petrov&quot;,
    &quot;is_admin&quot;: 1,
    &quot;password_hash&quot;: &quot;cSKSsy315E4EroxeDQrsxjTb6ijBxxbK&quot;,
    &quot;password_salt&quot;: &quot;vS5Otm&quot;,
}
</code></pre>

<p>And perhaps we would build a framework on top of SQLAlchemy which would let us access columns as <code>user.display_name</code> or <code>user.email</code> regardless whether it&rsquo;s an extracted indexed property or a buried _data element.</p>

<h3 id="process-adding-an-index">Process: Adding an index</h3>

<ol>
<li>Build a table with just a free-structure <code>_data</code> field.</li>
<li>Determine queries, extract relevant properties into indexed columns:

<ol>
<li>ALTER TABLE to add the column</li>
<li>Run full-scan query to populate new column with data</li>
<li>Add relevant index onto said column</li>
<li>Deprecate property from <code>_data</code> (optional, we could just assume that proper columns always supercede <code>_data</code> attributes)</li>
</ol></li>
</ol>

<h2 id="concerns">Concerns</h2>

<ul>
<li>Adding an index may affect database performance during the process, due to the data locality. With FriendFeed&rsquo;s approach, the indices are stored in their own tables which could even be sharded across databases, so this removes any performance concerns during schema transitions. On the other hand, FriendFeed&rsquo;s approach reduces data locality which increases the number of joins required to get desired data, and also reduces the semantic meaning of the tables thus making queries more complex.</li>
<li>Performing unexpected demographic analysis on large datasets would be much slower if the fields are stored in <code>_data</code> (such as age, gender, etc) since it would require a full table scan instead of an in-database aggregate query.</li>
<li>Parsing and storing the <code>_data</code> dictionary has some performance implications, too. cPickle is best for parsing performance, perhaps zlib-compressed cPickle is best for data size and parsing performance tradeoff, but no portability beyond Python. zlib-compressed JSON reduces data size and is portable across languages, but increases parsing time. Also, this could be done natively for <a href="http://www.postgresql.org/docs/current/static/hstore.html">PostgreSQL using HSTORE</a> (<a href="http://twitter.com/#!/__jek__/status/27975347844">via <strong>jek</strong></a>)</li>
<li>Tracking mutability is important, potentially hard to do elegantly.</li>
</ul>

    </div>
</section>
<div class="back">&larr; <a href="https://shazow.net/">Back to shazow.net</a></div>


<script type="text/javascript">
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    if (document.location.hostname != 'localhost') {
        ga('create', 'UA-407051-1', 'shazow.net');
    }

    ga('send', 'pageview');
</script>



</body>

</html>

